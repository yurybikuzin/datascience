{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Логистическая регрессия. Реализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации называется бинарной кросс-энтропией и записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i))),$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализация логистической регрессии будет основана на оптимизации функции ошибки градиентным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве экспериментальных данных возьмем датасет о доходах граждан в различных странах [Adult Income](https://archive.ics.uci.edu/ml/datasets/Adult) и сделаем необходимую предобработку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('./data/adult.data',\n",
    "                    names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                           'education-num', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'capital-gain',\n",
    "                           'capital-loss', 'hours-per-week', 'native-country', 'salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание датасета\n",
    "\n",
    "# with open('./data/adult.names', 'r') as f:\n",
    "#     names = f.read()\n",
    "# print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "\n",
       "        marital-status        occupation    relationship    race    sex  \\\n",
       "0        Never-married      Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse   Exec-managerial         Husband   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Избавиться от лишних признаков\n",
    "adult.drop(['native-country'], axis=1, inplace=True)\n",
    "# Сконвертировать целевой столбец в бинарные значения\n",
    "adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "# Сделать one-hot encoding для некоторых признаков\n",
    "adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0   39   77516             13          2174             0              40   \n",
       "1   50   83311             13             0             0              13   \n",
       "2   38  215646              9             0             0              40   \n",
       "3   53  234721              7             0             0              40   \n",
       "4   28  338409             13             0             0              40   \n",
       "\n",
       "   salary  workclass_ ?  workclass_ Federal-gov  workclass_ Local-gov  ...  \\\n",
       "0       0             0                       0                     0  ...   \n",
       "1       0             0                       0                     0  ...   \n",
       "2       0             0                       0                     0  ...   \n",
       "3       0             0                       0                     0  ...   \n",
       "4       0             0                       0                     0  ...   \n",
       "\n",
       "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
       "0                        0                        0                   0   \n",
       "1                        0                        0                   0   \n",
       "2                        0                        0                   0   \n",
       "3                        0                        0                   0   \n",
       "4                        0                        0                   1   \n",
       "\n",
       "   race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                         0                         0            0   \n",
       "1                         0                         0            0   \n",
       "2                         0                         0            0   \n",
       "3                         0                         0            1   \n",
       "4                         0                         0            1   \n",
       "\n",
       "   race_ Other  race_ White  sex_ Female  sex_ Male  \n",
       "0            0            1            0          1  \n",
       "1            0            1            0          1  \n",
       "2            0            1            0          1  \n",
       "3            0            0            0          1  \n",
       "4            0            0            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализовать нуждающиеся в этом признаки\n",
    "a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>salary</th>\n",
       "      <th>workclass_ ?</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Own-child</th>\n",
       "      <th>relationship_ Unmarried</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030671</td>\n",
       "      <td>-1.063611</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>0.148453</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837109</td>\n",
       "      <td>-1.008707</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-2.222153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.042642</td>\n",
       "      <td>0.245079</td>\n",
       "      <td>-0.420060</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.057047</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>-1.197459</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775768</td>\n",
       "      <td>1.408176</td>\n",
       "      <td>1.134739</td>\n",
       "      <td>-0.145920</td>\n",
       "      <td>-0.21666</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
       "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
       "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
       "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
       "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
       "\n",
       "   hours-per-week  salary  workclass_ ?  workclass_ Federal-gov  \\\n",
       "0       -0.035429       0             0                       0   \n",
       "1       -2.222153       0             0                       0   \n",
       "2       -0.035429       0             0                       0   \n",
       "3       -0.035429       0             0                       0   \n",
       "4       -0.035429       0             0                       0   \n",
       "\n",
       "   workclass_ Local-gov  ...  relationship_ Own-child  \\\n",
       "0                     0  ...                        0   \n",
       "1                     0  ...                        0   \n",
       "2                     0  ...                        0   \n",
       "3                     0  ...                        0   \n",
       "4                     0  ...                        0   \n",
       "\n",
       "   relationship_ Unmarried  relationship_ Wife  race_ Amer-Indian-Eskimo  \\\n",
       "0                        0                   0                         0   \n",
       "1                        0                   0                         0   \n",
       "2                        0                   0                         0   \n",
       "3                        0                   0                         0   \n",
       "4                        0                   1                         0   \n",
       "\n",
       "   race_ Asian-Pac-Islander  race_ Black  race_ Other  race_ White  \\\n",
       "0                         0            0            0            1   \n",
       "1                         0            0            0            1   \n",
       "2                         0            0            0            1   \n",
       "3                         0            1            0            0   \n",
       "4                         0            1            0            0   \n",
       "\n",
       "   sex_ Female  sex_ Male  \n",
       "0            0          1  \n",
       "1            0          1  \n",
       "2            0          1  \n",
       "3            0          1  \n",
       "4            1          0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить таблицу данных на матрицы X и y\n",
    "X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "y = adult['salary'].values\n",
    "\n",
    "# Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "m = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию sigmoid\n",
    "def sigmoid(X, theta):\n",
    "    return 1. / (1. + np.exp(-X.dot(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Реализовать функцию, вычисляющую градиент бинарной кросс-энтропии\n",
    "def calc_binary_cross_entropy_grad(X, y, theta):\n",
    "    n = X.shape[0]\n",
    "    grad = 1. / n * X.transpose().dot(sigmoid(X, theta) - y)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(theta, theta_grad, alpha):\n",
    "    return theta - alpha * theta_grad\n",
    "def optimize(X, y, grad_func, start_theta, alpha, n_iters):\n",
    "    theta = start_theta.copy()\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        theta_grad = grad_func(X, y, theta)\n",
    "        theta = gradient_step(theta, theta_grad, alpha)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизировать параметр линейной регрессии theta на всех данных\n",
    "theta = optimize(X, y, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.18220152e+00,  5.62066615e-01,  4.08394474e-01, -7.85036544e-01,\n",
       "        8.40399041e-01,  6.93612812e-03,  9.48510850e-01,  1.61096748e+00,\n",
       "        3.95775461e-01,  2.32468515e-01,  1.02420428e+00,  1.08787945e+00,\n",
       "        2.28275110e-02,  9.64814314e-01,  9.95948149e-01,  4.91984312e-01,\n",
       "        6.21876481e-01,  6.37883564e-01, -1.39716497e+00, -1.59850366e-02,\n",
       "        1.42333149e+00,  2.36520366e-01,  6.22907129e-01,  5.53494533e-01,\n",
       "        8.35398252e-01, -4.28230037e-01,  6.90788800e-01,  8.11280626e-01,\n",
       "        7.79500017e-02,  5.20449527e-01,  1.59897859e-01,  6.18223280e-01,\n",
       "       -2.97874470e-01,  9.87311090e-01,  6.08930383e-01,  8.58881427e-01,\n",
       "        2.58558666e-01,  3.62299888e-01,  4.35222964e-01,  3.38583874e-01,\n",
       "        7.61509306e-01,  2.21719660e+00,  6.11752440e-01, -1.29220590e-02,\n",
       "        3.38009780e-01,  5.34420479e-01,  6.46143233e-01,  9.33962074e-01,\n",
       "        3.36378365e-01,  3.24397258e-01,  3.30697269e-01,  1.02543563e+00,\n",
       "        9.74747564e-01, -7.81877921e-02,  9.78308166e-01,  9.09710550e-01,\n",
       "        1.14915955e+00,  4.24799786e-01, -6.37888463e-01,  5.89057982e-01,\n",
       "        7.68917996e-01,  8.85025416e-01,  9.88443132e-04,  1.05574662e+00,\n",
       "        7.95663040e-01, -3.15524980e-01,  8.98087390e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_logisitc_metrics(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'acc = {acc:.2f} F1-score = {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.65\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-93ff4a090195>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint_logisitc_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "# Сделать предсказания на тренировочной выборке и\n",
    "# посчитать значение метрики accuracy и F1-score\n",
    "y_pred = sigmoid(X, theta) > 0.5\n",
    "print_logisitc_metrics(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23091,  1629],\n",
       "       [ 3242,  4599]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics  \n",
    "sklearn.metrics.confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.85 F1-score = 0.66\n"
     ]
    }
   ],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
    "theta = optimize(X_train, y_train, calc_binary_cross_entropy_grad, np.ones(m), 1., 300)\n",
    "y_pred = sigmoid(X_valid, theta) > 0.5\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисовать ROC кривую\n",
    "def calc_and_plot_roc(y_true, y_pred_proba):\n",
    "    # Посчитать значения ROC кривой и значение площади под кривой AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "    plt.title('Receiver Operating Characteristic', fontsize=15)\n",
    "    plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "    plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "    plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислить вероятности принадлежности классу 1 для каждого объекта из валидационной выборки\n",
    "y_pred_proba = sigmoid(X_valid, theta)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3B.6.1\n",
    "2/2 points (graded)\n",
    "Постройте модель логистической регрессии при помощи sklearn. Используйте параметры по умолчанию, обучите на всей выборке и посчитайте F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.84 F1-score = 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver=\"lbfgs\", max_iter=10000)\n",
    "#X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "#y = adult['salary'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print_logisitc_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4563,  690],\n",
       "       [ 334,  926]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics  \n",
    "sklearn.metrics.confusion_matrix(y_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct answer is:\n",
    "  ```\n",
    "  [\n",
    "      [23028, 1692],\n",
    "      [3128, 4713],\n",
    "  ]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3B.6.3\n",
    "0/2 points (graded)\n",
    "Постройте ROC-кривую и посчитайте  для классификатора из задачи 3.6.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a22ebf780>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.title('Receiver Operating Characteristic', fontsize=15)\n",
    "plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3B.6.4\n",
    "2/2 points (graded)\n",
    "Постройте модель логистической регрессии при помощи sklearn без регуляризации. Чему равен F1-score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(penalty=\"none\", solver=\"newton-cg\")\n",
    "#X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "#y = adult['salary'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "round(sklearn.metrics.f1_score(y_pred, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3B.6.5\n",
    "0.0/2.0 points (graded)\n",
    "Переберите коэффициенты l2-регуляризации от 0.01 до 1 с шагом 0.01 и определите, на каком из них модель логистической регрессии из sklearn даёт наибольший F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_max: 0.6755430974071478, i_max: 61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "f1_max = 0\n",
    "i_max = 0\n",
    "\n",
    "for i in range(1, 101):\n",
    "    model = LogisticRegression(penalty=\"l2\", solver=\"newton-cg\", C=i/100)    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = sklearn.metrics.f1_score(y_pred, y_test)\n",
    "    if f1_max < f1:\n",
    "        f1_max = f1\n",
    "        i_max = i\n",
    "print(f'f1_max: {f1_max}, i_max: {i_max}')\n",
    "# round(sklearn.metrics.f1_score(y_pred, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Добавление регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Оборачивание линейной регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegOptimizer():\n",
    "    def __init__(self, alpha, n_iters):\n",
    "        self.theta = None\n",
    "        self._alpha = alpha\n",
    "        self._n_iters = n_iters\n",
    "    \n",
    "    def gradient_step(self, theta, theta_grad):\n",
    "        return theta - self._alpha * theta_grad\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def optimize(self, X, y, start_theta, n_iters):\n",
    "        theta = start_theta.copy()\n",
    "\n",
    "        for _ in range(n_iters):\n",
    "            theta_grad = self.grad_func(X, y, theta)\n",
    "            theta = self.gradient_step(theta, theta_grad)\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m = X.shape[1]\n",
    "        start_theta = np.ones(m)\n",
    "        self.theta = self.optimize(X, y, start_theta, self._n_iters)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg(RegOptimizer):\n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = X.dot(self.theta)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f'MSE = {mse:.2f}, RMSE = {rmse:.2f}')\n",
    "def prepare_boston_data():\n",
    "    data = load_boston()\n",
    "    X, y = data['data'], data['target']\n",
    "    # Нормализовать даннные с помощью стандартной нормализации\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinReg(0.01, 500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Оборачивание логистической регрессии в класс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(RegOptimizer):\n",
    "    def sigmoid(self, X, theta):\n",
    "        return 1. / (1. + np.exp(-X.dot(theta)))\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(X, self.theta)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.theta is None:\n",
    "            raise Exception('You should train the model first')\n",
    "        \n",
    "        y_pred = self.predict_proba(X) > 0.5\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         United-States\n",
       "1         United-States\n",
       "2         United-States\n",
       "3         United-States\n",
       "4                  Cuba\n",
       "5         United-States\n",
       "6               Jamaica\n",
       "7         United-States\n",
       "8         United-States\n",
       "9         United-States\n",
       "10        United-States\n",
       "11                India\n",
       "12        United-States\n",
       "13        United-States\n",
       "14                    ?\n",
       "15               Mexico\n",
       "16        United-States\n",
       "17        United-States\n",
       "18        United-States\n",
       "19        United-States\n",
       "20        United-States\n",
       "21        United-States\n",
       "22        United-States\n",
       "23        United-States\n",
       "24        United-States\n",
       "25        United-States\n",
       "26        United-States\n",
       "27                South\n",
       "28        United-States\n",
       "29        United-States\n",
       "              ...      \n",
       "32531     United-States\n",
       "32532     United-States\n",
       "32533             Japan\n",
       "32534     United-States\n",
       "32535     United-States\n",
       "32536     United-States\n",
       "32537     United-States\n",
       "32538     United-States\n",
       "32539     United-States\n",
       "32540     United-States\n",
       "32541     United-States\n",
       "32542     United-States\n",
       "32543     United-States\n",
       "32544     United-States\n",
       "32545     United-States\n",
       "32546     United-States\n",
       "32547            Mexico\n",
       "32548     United-States\n",
       "32549     United-States\n",
       "32550     United-States\n",
       "32551     United-States\n",
       "32552     United-States\n",
       "32553            Taiwan\n",
       "32554     United-States\n",
       "32555     United-States\n",
       "32556     United-States\n",
       "32557     United-States\n",
       "32558     United-States\n",
       "32559     United-States\n",
       "32560     United-States\n",
       "Name: native-country, Length: 32561, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult = pd.read_csv('./data/adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "adult['native-country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_adult_data():\n",
    "    adult = pd.read_csv('./data/adult.data',\n",
    "                        names=['age', 'workclass', 'fnlwgt', 'education',\n",
    "                               'education-num', 'marital-status', 'occupation',\n",
    "                               'relationship', 'race', 'sex', 'capital-gain',\n",
    "                               'capital-loss', 'hours-per-week', 'native-country', 'salary'])\n",
    "    \n",
    "    # Избавиться от лишних признаков\n",
    "    adult.drop(['native-country'], axis=1, inplace=True)\n",
    "    # Сконвертировать целевой столбец в бинарные значения\n",
    "    adult['salary'] = (adult['salary'] != ' <=50K').astype('int32')\n",
    "    # Сделать one-hot encoding для некоторых признаков\n",
    "    adult = pd.get_dummies(adult, columns=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex'])\n",
    "    \n",
    "    # Нормализовать нуждающиеся в этом признаки\n",
    "    a_features = adult[['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']].values\n",
    "    norm_features = (a_features - a_features.mean(axis=0)) / a_features.std(axis=0)\n",
    "    adult.loc[:, ['age', 'education-num', 'hours-per-week', 'fnlwgt', 'capital-gain', 'capital-loss']] = norm_features\n",
    "    \n",
    "    # Разбить таблицу данных на матрицы X и y\n",
    "    X = adult[list(set(adult.columns) - set(['salary']))].values\n",
    "    y = adult['salary'].values\n",
    "\n",
    "    # Добавить фиктивный столбец единиц (bias линейной модели)\n",
    "    X = np.hstack([np.ones(X.shape[0])[:, np.newaxis], X])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogReg(1., 300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случаях линейной и логистической регрессии будем добавлять к функции ошибки регуляризующую часть как:\n",
    "$$\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $\\theta$ — вектор параметров линейной модели без фиктивного признака (intercept/bias term), $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Добавление регуляризатора в линейную регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После добавления регуляризации функция ошибки линейной регрессии будет выглядеть следующим образом:\n",
    "$$L=\\frac{1}{2n} * \\sum_{i=1}^{n}{(y_i - \\theta^Tx_i)^2} + \\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2}$$\n",
    "А ее градиент по параметру $\\theta$:\n",
    "$$\\nabla L = \\frac{1}{n}\\sum_{i=1}^{n}{(\\theta^Tx_i - y_i) \\cdot x_i} + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j} = \\frac{1}{n}X^T(X\\theta - y) + \\frac{\\lambda}{m}\\sum_{j=1}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinRegRegularized(LinReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LinRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(X.dot(theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinRegRegularized(alpha=0.01, lambd=0.05, n_iters=500)\n",
    "X, y = prepare_boston_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_valid)\n",
    "print_regression_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Добавление регуляризатора в логистическую регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ошибки для логистической регрессии в случае бинарной классификации с регуляризатором записывается следующим образом:\n",
    "$$L=-\\frac{1}{n}(y_i \\log h_{\\theta}(x_i) + (1-y_i) \\log(1-h_{\\theta}(x_i)))+\\frac{\\lambda}{2m}\\sum_{j}^{m}{\\theta_j^2},$$\n",
    "где $x_i$ — вектор признаков $i$-го примера из обучающей выборки, $y_i$ — истинный класс для соответствующего примера (0 или 1), $n$ — число примеров в обучающей выборке, $m$ — количество нефиктивных признаков, $\\lambda$ — параметр регуляризации, $h_{\\theta}(x)$ — sigmoid функция, равная:\n",
    "$$h_{\\theta}(x)=\\frac{1}{1+\\exp^{-\\theta x}},$$\n",
    "где $\\theta$ — вектор параметров логистической регрессии, $x$ - вектор признаков объекта из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соответствующий градиент функции ошибки равен:\n",
    "$$\\nabla L=\\frac{1}{n}\\sum_{i=1}^{n}{(h_{\\theta}(x_i)-y_i)x_i}+\\frac{\\lambda}{m}\\sum_{j}^{m}{\\theta_j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegRegularized(LogReg):\n",
    "    def __init__(self, alpha, lambd, n_iters):\n",
    "        super(LogRegRegularized, self).__init__(alpha, n_iters)\n",
    "        self._lambd = lambd\n",
    "    \n",
    "    def grad_func(self, X, y, theta):\n",
    "        n = X.shape[0]\n",
    "        grad = 1. / n * X.transpose().dot(self.sigmoid(X, theta) - y)\n",
    "        grad_term = self._lambd * np.mean(theta)\n",
    "\n",
    "        return grad + grad_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogRegRegularized(alpha=1., lambd=1., n_iters=300)\n",
    "X, y = prepare_adult_data()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбить выборку на train/valid, оптимизировать theta,\n",
    "# сделать предсказания и посчитать ошибку F1-score\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_valid)\n",
    "\n",
    "print_logisitc_metrics(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_valid)\n",
    "calc_and_plot_roc(y_valid, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.13839024130401"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "vis_data = pd.read_csv(\"./data/train.csv\", encoding = 'ISO-8859-1', low_memory = False)\n",
    "# Напишите ваш код ниже\n",
    "train, test = train_test_split(vis_data, test_size=0.3, shuffle=False)\n",
    "result = test.payment_amount.mean()\n",
    "result\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_true = [1.23, 2.35, 2.75]\n",
    "y_pred = [1.01, 12.3, 2.74]\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import math\n",
    "round(math.sqrt(mse(y_true, y_pred)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.75"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [1.23, 2.35, 2.75]\n",
    "y_pred = [1.01, 12.3, 2.74]\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import math\n",
    "round(math.sqrt(mse(y_true, y_pred)), 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
