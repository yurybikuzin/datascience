{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В 6 модуле мы обучали логистическую регрессию для классификации людей в группу риска ишемической болезни сердца в 10-летней перспрективе по датасету framingham.csv.\n",
    "\n",
    "Если вы помните, модель получилась плохая: несмотря на довольно большую долю верно классифицированных пациентов (около 85%), она очень плохо определяла пациентов группы риска. Чувствительность была нулевая или почти нулевая, а ошибка 2 рода (ложно-отрицательные результаты среди пациентов группы риска) большая.\n",
    "\n",
    "Для медицинского теста это плохо, так как врач пропустит много пациентов с высоким риском заболеть.\n",
    "\n",
    "Проблема заключается вот в чем: в обучающей выборке здоровых пациентов намного больше, чем больных. В этом случае классификатору \"выгодно\" обучиться так, чтобы хорошо определять бОльший класс, так как он тогда чаще будет угадывать.\n",
    "\n",
    "Попробуем улучшить работу классификатора двумя способами: настроив веса в логистической регрессии и сделав undersampling здоровых пациентов в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем датасет и избавимся от нулевых строк\n",
    "df = pd.read_csv('framingham.csv')\n",
    "df.dropna(axis=0,inplace=True) #избавляемся от строчек с пропущенными значениями\n",
    "\n",
    "# разбиваем датафрейм на две части, dfx - параметры, dfy - целевая переменная. \n",
    "dfx = df.drop('TenYearCHD', axis = 1)\n",
    "dfy = df[['TenYearCHD']] \n",
    "\n",
    "# разбиваем датасет на train и test выборку в соотношениии 80% train / 20% test случайным образом\n",
    "# фиксируем random_state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx, dfy, test_size=0.2, random_state=17) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Способ\n",
    "\n",
    "Его идея заключается в том, что мы добавим на этапе обучения бОльший штраф за ошибки для более редкого класса, тем самым увеличивая чувствительность классификатора к этому классу. \n",
    "\n",
    "Среди параметров LogisticRegression есть class_weight. Он может иметь 3 состояния:\n",
    "\n",
    "1. class_weight=None означает, что мы обучаем регрессию как обычно, без доп. настроек. Так мы делали в практике 6 модуля \n",
    "2. class_weight='balanced' задает веса обратно пропорционально количеству элементов в каждом классе. Например, если в выборке будет 1000 здоровых пациентов и 100 больных, то веса будут относиться как 1:10. В описании параметров на https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression есть формула, по которой считаются коэффициенты.\n",
    "3. class_weight=dict - можно задать веса самостоятельно с формате словаря."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала давайте попробуем, как работает логистическая регрессия с весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced') \n",
    "# обучаем\n",
    "model = lm.fit(X_train, y_train.values.ravel()) \n",
    "# сделаем prediction классов на всей тестовой выборке\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "# можно увидеть, что она ведет себя намного лучше, чем для модели без весов!\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, мы сущесвтенно улучшили чувствительность классификатора.\n",
    "\n",
    "Давайте посмотрим на метрики качества:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cnf_matrix[0,0] # True Negative\n",
    "TP = cnf_matrix[1,1] # True Positive\n",
    "FN = cnf_matrix[1,0] # False Negative\n",
    "FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "Ac = lm.score(X_test, y_test)\n",
    "Sens = TP/(TP+FN) \n",
    "Sp = TN/(TN+FP)\n",
    "P = TP/(TP+FP)\n",
    "typeI = FP/(FP+TN)\n",
    "typeII = FN/(FN+TP)\n",
    "    \n",
    "print('Accuracy: ', Ac)\n",
    "print('Sensitivity: ', Sens)\n",
    "print('Specificity: ', Sp)\n",
    "print('Pricision: ', P)\n",
    "print('Type I error rate: ', typeI)\n",
    "print('Type II error rate: ', typeII)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy модели стала меньше, чем в простом случае, но зато ошибка второго рода тоже уменьшилась, что для нас в данном случае важнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы не делать 100500 копипастов, создадим функцию print_logit_scores\n",
    "# которая будет обучать регрессию заданным способом и выводить разные метрики качества\n",
    "\n",
    "def print_logit_scores(data_train, target_train, data_test, target_test, model_type, weights):\n",
    "    \n",
    "    # data_train, target_train, data_test, target_test - это обучающие и тестовые данные\n",
    "    # model_type задает один из 3 типов обучения: 'n' - None, 'b' - balanced, 'w' - заданные пользователем веса\n",
    "    # w - вектор весов. Используется только для model_type = 'w'\n",
    "    \n",
    "    if (model_type == 'n'): # обучаем с равными весами\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight=None)    \n",
    "    elif (model_type == 'b'): # балансируем веса, как предлагают разработчики sklearn\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "    elif (model_type == 'w'): # балансируем веса самостоятельно\n",
    "        lm = linear_model.LogisticRegression(solver='liblinear', class_weight={0:weights[0], 1:weights[1]}) \n",
    "\n",
    "    # обучаем\n",
    "    model = lm.fit(data_train, target_train.values.ravel()) \n",
    "\n",
    "    # сделаем prediction классов на всей тестовой выборке\n",
    "    target_pred = lm.predict(data_test)\n",
    "\n",
    "    # строим confusion matrix - таблицу правильных и неправильных предсказаний\n",
    "    cnf_matrix = metrics.confusion_matrix(target_test, target_pred)\n",
    "\n",
    "    TN = cnf_matrix[0,0] # True Negative\n",
    "    TP = cnf_matrix[1,1] # True Positive\n",
    "    FN = cnf_matrix[1,0] # False Negative\n",
    "    FP = cnf_matrix[0,1] # False Positive\n",
    "    \n",
    "    Ac = lm.score(data_test, target_test)\n",
    "    Sens = TP/(TP+FN) \n",
    "    Sp = TN/(TN+FP)\n",
    "    P = TP/(TP+FP)\n",
    "    typeI = FP/(FP+TN)\n",
    "    typeII = FN/(FN+TP)\n",
    "    \n",
    "    print('Accuracy: ', Ac)\n",
    "    print('Sensitivity: ', Sens)\n",
    "    print('Specificity: ', Sp)\n",
    "    print('Precision: ', P)\n",
    "    print('Type I error rate: ', typeI)\n",
    "    print('Type II error rate: ', typeII)\n",
    "    \n",
    "    return [Ac,Sens,Sp,P,typeI,typeII] # возвращаем список метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "интуитивно хочется поделить веса обратно пропорционально количеству элементов в классе, оставив сумму 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share = y_train['TenYearCHD'].value_counts()\n",
    "w0 = share[1]/(share[0]+share[1])\n",
    "w = np.array([w0,1-w0])\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разработчики sklearn предлагают балансировать веса по другому правилу. При этом они тоже будут обратно пропорциональны количествую элементов, но сумма будет уже не 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train['TenYearCHD']) # считает количество вхождений 0 и 1 в y_train['TenYearCHD']\n",
    "w_b = y_train.shape[0]/ (2*np.bincount(y_train['TenYearCHD']))\n",
    "w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Давайте убедимся, что отношения весов действительно одинаковые\n",
    "# При этом бОльший по размеру класс (нулевой, то есть здоровые пациенты) имеет мЕньший вес\n",
    "print('отношение интуитивных весов: ', w[0]/w[1])\n",
    "print('отношение balanced весов: ', w_b[0]/w_b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравним \n",
    "print('ручная балансировка по правилу balanced')\n",
    "m1 = print_logit_scores(X_train, y_train, X_test, y_test, 'w', w_b) # ручная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('встроенная балансировка по правилу balanced')\n",
    "m2 = print_logit_scores(X_train, y_train, X_test, y_test, 'b', w) # встроенная балансировка по правилу balanced\n",
    "print('\\n')\n",
    "print ('без балансировки весов')\n",
    "m3 = print_logit_scores(X_train, y_train, X_test, y_test, 'n', w) # без балансировки весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Способ\n",
    "\n",
    "Его идея заключается в том, чтобы уравнять доли \"здоровых\" и \"больных\" в обучающей выборке.\n",
    "\n",
    "Каким образом?\n",
    "\n",
    "Очень просто: из всех \"здоровых\" пациентов в обучающей выборке сделам подвыборку того же размера, сколько у нас \"больных\". Например, если в обучающей выборке 1000 \"здоровых\" и 100 \"больных\", то мы из этой 1000 случайным образом выберем 100. Это называется undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нам понадобится новая библиотека imblearn\n",
    "# в моей версии Anaconda (2019.03) она не предустановлена\n",
    "# возможно, вам тоже нужно установить ее самостоятельно\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# освежите в памяти, что показывает share и что значит share[1]\n",
    "# параметр ratio в RandomUnderSampler задается словарем: \n",
    "# 1: - желаемое количество объектов класса 1\n",
    "# 0: - желаемое количество объектов класса 0\n",
    "\n",
    "# задаем параметры выборки:\n",
    "sampler = RandomUnderSampler(ratio={1: share[1], 0: share[1]})\n",
    "\n",
    "# сам unpersampling выполняется здесь:\n",
    "X_train_under_np, y_train_under_np = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "# преобразуем в DataFrame, чтобы скормить логистической регрессии\n",
    "X_train_under = pd.DataFrame(X_train_under_np)\n",
    "y_train_under = pd.DataFrame(y_train_under_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисляем качество модели с undersampling\n",
    "# как вы думаете, почему в качестве model_type здесь можно взять 'n'?\n",
    "m_u = print_logit_scores(X_train_under, y_train_under, X_test, y_test, 'n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сравните результаты со встроенной балансировкой на всей обучающей выборке\n",
    "# как вы думаете, какой есть существенный недостаток у undersampling по сравнению с балансировкой весов?\n",
    "m2 = print_logit_scores(X_train, y_train, X_test, y_test, 'b', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
